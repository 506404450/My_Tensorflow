{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MINST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MINST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MINST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MINST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "minst = input_data.read_data_sets('MINST_data', one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;使用交互式对话，不用一次性构建整个图再运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;设置超参数，这里的输入是图片的一行，每行作为时序中的一帧，time_step是时序的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "iteration = 20000\n",
    "batch_size = 128\n",
    "\n",
    "input_size = 28\n",
    "time_step = 28\n",
    "neurons = 128\n",
    "classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = tf.placeholder(tf.float32, [None, time_step, input_size])\n",
    "ys = tf.placeholder(tf.float32, [None, classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;设置权重,这里权重分为输入权重与输出权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight = {\n",
    "    'in':tf.Variable(tf.random_normal([input_size, neurons])),\n",
    "    'out':tf.Variable(tf.random_normal([neurons, classes]))\n",
    "}\n",
    "bias = {\n",
    "    'in':tf.Variable(tf.constant(0.1, shape = [neurons, ])),\n",
    "    'out':tf.Variable(tf.constant(0.1, shape = [classes, ]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;第一次reshape中的 -1 是指该维先不计算，最后通过已确定的维度来算，这里共有X原维度为[batch_size = 128, time_step = 28, input_size = 28],也就是共有128 \\* 28 \\* 28个元素。reshape之后第二维为28个元素即一行像素,则第一维为 128 \\* 28 \\* 28 / 28 = 128 \\* 28。其实是将原数据转化为了若干个28像素的输入,每个28像素即一个时序帧的输入   \n",
    "&emsp;第二次reshape同理,将结果转换回输入时的格式  \n",
    "&emsp;BasicLSTMCell是最简单的LSTMCell,只含一个forget门、一个input门、一个output门。state_is_tuple = True,是指以tuple形式(c_state, m_state)返回cell state,其中m_state其实就是输出。lstm_cell.zero_state用0来初始化前一状态  \n",
    "&emsp;dynamic_rnn中的time_major函数决定了输出的格式,time_major = false的话输出格式为[batch_size, time_step, neurons],否则batch_size与time_step的位置互换  \n",
    "&emsp;out储存了每一步的输出,是一个list,而states只保存最后一步的states,因此states[1]就是最后的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(X, W, B):\n",
    "    X = tf.reshape(X, [-1, input_size])\n",
    "    in_ = tf.matmul(X, W['in']) + B['in']\n",
    "    in_ = tf.reshape(in_, [-1, time_step, neurons])\n",
    "    \n",
    "    first_lstm_cell = tf.contrib.rnn.BasicLSTMCell(neurons, forget_bias = 1.0, state_is_tuple = True)\n",
    "    init_state = first_lstm_cell.zero_state(batch_size, dtype = tf.float32)\n",
    "    \n",
    "    out_, states_ = tf.nn.dynamic_rnn(first_lstm_cell, in_, initial_state = init_state, time_major = False)\n",
    "    \n",
    "    results = tf.matmul(states_[1], W['out']) + B['out']\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;这里的softmax_cross_entropy_with_logits实际是将softmax与cross_entropy合为一步,因为通常softmax的损失函数就是cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = RNN(xs, weight, bias)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = ys))\n",
    "train = tf.train.AdamOptimizer(lr).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.arg_max(pred, 1), tf.arg_max(ys, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.171875\n",
      "0.71875\n",
      "0.695312\n",
      "0.78125\n",
      "0.859375\n",
      "0.828125\n",
      "0.90625\n",
      "0.914062\n",
      "0.882812\n",
      "0.914062\n",
      "0.898438\n",
      "0.914062\n",
      "0.929688\n",
      "0.898438\n",
      "0.9375\n",
      "0.96875\n",
      "0.9375\n",
      "0.976562\n",
      "0.960938\n",
      "0.945312\n",
      "0.960938\n",
      "0.953125\n",
      "0.984375\n",
      "0.953125\n",
      "0.96875\n",
      "0.976562\n",
      "0.960938\n",
      "0.976562\n",
      "0.953125\n",
      "0.953125\n",
      "0.9375\n",
      "0.953125\n",
      "0.992188\n",
      "0.960938\n",
      "0.945312\n",
      "0.96875\n",
      "0.976562\n",
      "0.953125\n",
      "0.96875\n",
      "0.992188\n",
      "0.945312\n",
      "0.96875\n",
      "0.984375\n",
      "0.976562\n",
      "0.992188\n",
      "0.976562\n",
      "0.976562\n",
      "0.96875\n",
      "0.96875\n",
      "0.960938\n",
      "0.992188\n",
      "0.984375\n",
      "0.976562\n",
      "0.984375\n",
      "0.976562\n",
      "0.976562\n",
      "0.984375\n",
      "1.0\n",
      "0.976562\n",
      "0.984375\n",
      "0.984375\n",
      "0.976562\n",
      "0.984375\n",
      "1.0\n",
      "0.984375\n",
      "0.96875\n",
      "0.976562\n",
      "0.984375\n",
      "1.0\n",
      "0.976562\n",
      "0.984375\n",
      "0.960938\n",
      "0.96875\n",
      "0.992188\n",
      "0.976562\n",
      "0.992188\n",
      "0.992188\n",
      "0.984375\n",
      "1.0\n",
      "0.96875\n",
      "0.96875\n",
      "0.976562\n",
      "0.960938\n",
      "0.992188\n",
      "0.976562\n",
      "0.976562\n",
      "0.984375\n",
      "0.992188\n",
      "1.0\n",
      "0.992188\n",
      "0.992188\n",
      "0.992188\n",
      "0.984375\n",
      "1.0\n",
      "1.0\n",
      "0.992188\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.976562\n",
      "0.984375\n",
      "1.0\n",
      "1.0\n",
      "0.976562\n",
      "0.992188\n",
      "0.96875\n",
      "1.0\n",
      "0.984375\n",
      "0.984375\n",
      "0.96875\n",
      "0.992188\n",
      "0.976562\n",
      "1.0\n",
      "1.0\n",
      "0.992188\n",
      "0.984375\n",
      "0.992188\n",
      "0.96875\n",
      "1.0\n",
      "1.0\n",
      "0.992188\n",
      "1.0\n",
      "0.992188\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.992188\n",
      "0.992188\n",
      "1.0\n",
      "0.976562\n",
      "0.984375\n",
      "0.992188\n",
      "1.0\n",
      "1.0\n",
      "0.992188\n",
      "0.984375\n",
      "1.0\n",
      "0.984375\n",
      "0.992188\n",
      "0.992188\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.984375\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.976562\n",
      "0.984375\n",
      "0.992188\n",
      "0.984375\n",
      "0.992188\n",
      "1.0\n",
      "0.992188\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.976562\n",
      "0.992188\n",
      "0.984375\n",
      "0.992188\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.992188\n",
      "0.992188\n",
      "0.992188\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.984375\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.992188\n",
      "0.984375\n",
      "0.992188\n",
      "0.984375\n",
      "1.0\n",
      "0.984375\n",
      "0.984375\n",
      "0.992188\n",
      "0.976562\n",
      "0.992188\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.992188\n",
      "0.992188\n",
      "1.0\n",
      "0.984375\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.984375\n",
      "0.992188\n",
      "0.992188\n",
      "0.992188\n",
      "1.0\n",
      "0.992188\n",
      "0.992188\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(20000):\n",
    "    batch_xs, batch_ys = minst.train.next_batch(batch_size)\n",
    "    batch_xs = batch_xs.reshape([batch_size, time_step, input_size])\n",
    "    sess.run(train, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "    if step % 20 == 0:\n",
    "        print(sess.run(accuracy, feed_dict={xs: batch_xs, ys: batch_ys}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
